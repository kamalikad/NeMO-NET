
# coding: utf-8

# # test keras-fcn functions

# In[6]:


import sys
# load ipython-pytest
sys.path.append('./utils/tests/')
get_ipython().run_line_magic('load_ext', 'ipython_pytest')
import pytest
#import ipython_pytest


# In[9]:


get_ipython().run_cell_magic('pytest', '', "\n#test_layers.py\n\nimport pytest\nimport numpy as np\nimport keras.backend as K\nfrom keras_fcn.layers import CroppingLike2D, BilinearUpSampling2D\nfrom keras.utils.test_utils import keras_test\n\n\n@keras_test\ndef test_bilinear_upsampling_2d():\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 5\n    input_len_dim2 = 5\n    target_len_dim1 = 8\n    target_len_dim2 = 8\n\n    for data_format in ['channels_first', 'channels_last']:\n        if data_format == 'channels_first':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2)\n            target = np.random.rand(num_samples, stack_size,\n                                    target_len_dim1, target_len_dim2)\n            expected_output_shape = (2, 2, 8, 8)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    stack_size)\n            target = np.random.rand(num_samples, target_len_dim1,\n                                    target_len_dim2, stack_size)\n            expected_output_shape = (2, 8, 8, 2)\n        # shape test\n        layer = BilinearUpSampling2D(target_shape=target.shape,\n                                     data_format=data_format)\n        output = layer(K.variable(inputs))\n        assert K.int_shape(output) == expected_output_shape\n\n\n@keras_test\ndef test_cropping_like_2d():\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 9\n    input_len_dim2 = 9\n    target_len_dim1 = 5\n    target_len_dim2 = 5\n    offset = (2, 2)\n\n    for data_format in ['channels_first', 'channels_last']:\n        if data_format == 'channels_first':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2)\n            target = np.random.rand(num_samples, stack_size,\n                                    target_len_dim1, target_len_dim2)\n            invalid_target = np.random.rand(num_samples, stack_size,\n                                            input_len_dim1 + 1,\n                                            input_len_dim2 + 1)\n            expected_output = inputs[:,\n                                     :,\n                                     offset[0]: offset[0] + target_len_dim1,\n                                     offset[1]: offset[1] + target_len_dim2]\n            expected_output_shape = (2, 2, 5, 5)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    stack_size)\n            target = np.random.rand(num_samples, target_len_dim1,\n                                    target_len_dim2, stack_size)\n            invalid_target = np.random.rand(num_samples, input_len_dim1 + 1,\n                                            input_len_dim2 + 1, stack_size)\n            expected_output = inputs[:,\n                                     offset[0]: offset[0] + target_len_dim1,\n                                     offset[1]: offset[1] + target_len_dim2,\n                                     :]\n            expected_output_shape = (2, 5, 5, 2)\n        # basic test\n        layer = CroppingLike2D(target_shape=target.shape,\n                               offset=2, data_format=data_format)\n        assert layer.offset == (2, 2)\n        layer = CroppingLike2D(target_shape=target.shape,\n                               offset=offset, data_format=data_format)\n        # correctness test\n        output = layer(K.variable(inputs))\n        assert K.int_shape(output) == expected_output_shape\n        np_output = K.eval(output)\n        assert np.allclose(np_output, expected_output)\n        # 'centered' test\n        layer = CroppingLike2D(target_shape=target.shape,\n                               offset='centered', data_format=data_format)\n        output = layer(K.variable(inputs))\n        np_output = K.eval(output)\n        assert np.allclose(np_output, expected_output)\n\n        # Test invalid use cases\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=target.shape,\n                                   offset=(5, 2),\n                                   data_format=data_format)\n            output = layer(K.variable(inputs))\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=target.shape,\n                                   offset=(2, 5),\n                                   data_format=data_format)\n            output = layer(K.variable(inputs))\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=target.shape,\n                                   offset=[3, 3, 3],\n                                   data_format=data_format)\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=invalid_target.shape,\n                                   offset='centered', data_format=data_format)\n            output = layer(K.variable(inputs))")


# In[10]:


get_ipython().run_cell_magic('pytest', '', "\n#test_blocks.py\n\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input\nfrom keras_fcn.blocks import (\n    vgg_conv,\n    vgg_fc,\n    vgg_deconv,\n    vgg_score\n)\n\n\ndef test_vgg_conv():\n    if K.image_data_format() == 'channels_first':\n        x = Input(shape=(3, 224, 224))\n        y1_shape = (None, 64, 112, 112)\n        y2_shape = (None, 128, 56, 56)\n    else:\n        x = Input(shape=(224, 224, 3))\n        y1_shape = (None, 112, 112, 64)\n        y2_shape = (None, 56, 56, 128)\n\n    block1 = vgg_conv(filters=64, convs=2, block_name='block1')\n    y = block1(x)\n    assert K.int_shape(y) == y1_shape\n\n    block2 = vgg_conv(filters=128, convs=2, block_name='block2')\n    y = block2(y)\n    assert K.int_shape(y) == y2_shape\n\n\ndef test_vgg_fc():\n    if K.image_data_format() == 'channels_first':\n        x1 = K.variable(np.random.random((1, 512, 14, 14)))\n        y1_shape = (1, 512, 8, 8)\n    else:\n        x1 = K.variable(np.random.random((1, 14, 14, 512)))\n        y1_shape = (1, 8, 8, 512)\n\n\ndef test_vgg_deconv():\n    if K.image_data_format() == 'channels_first':\n        x1 = K.variable(np.random.random((1, 512, 8, 8)))\n        y1_shape = (1, 21, 18, 18)\n        x2 = K.variable(np.random.random((1, 512, 27, 27)))\n        y2_shape = (1, 21, 38, 38)\n        x3 = K.variable(np.random.random((1, 256, 53, 53)))\n        y3_shape = (1, 21, 312, 312)\n    else:\n        x1 = K.variable(np.random.random((1, 8, 8, 512)))\n        y1_shape = (1, 18, 18, 21)\n        x2 = K.variable(np.random.random((1, 27, 27, 512)))\n        y2_shape = (1, 38, 38, 21)\n        x3 = K.variable(np.random.random((1, 53, 53, 256)))\n        y3_shape = (1, 312, 312, 21)\n\n    upscore1 = vgg_deconv(classes=21)(x1, None)\n    assert K.int_shape(upscore1) == y1_shape\n    assert not np.any(np.isnan(K.eval(upscore1)))\n\n    upscore2 = vgg_deconv(classes=21)(x2, upscore1)\n    assert K.int_shape(upscore2) == y2_shape\n    assert not np.any(np.isnan(K.eval(upscore2)))\n\n    upscore3 = vgg_deconv(classes=21, kernel_size=(16, 16),\n                          strides=(8, 8))(x3, upscore2)\n    assert K.int_shape(upscore3) == y3_shape\n    assert not np.any(np.isnan(K.eval(upscore3)))\n\n\ndef test_vgg_score():\n    if K.image_data_format() == 'channels_first':\n        x1 = K.variable(np.random.random((1, 3, 224, 224)))\n        x2 = K.variable(np.random.random((1, 21, 312, 312)))\n        y_shape = (1, 21, 224, 224)\n    else:\n        x1 = K.variable(np.random.random((1, 224, 224, 3)))\n        x2 = K.variable(np.random.random((1, 312, 312, 21)))\n        y_shape = (1, 224, 224, 21)\n    score = vgg_score(crop_offset='centered')(x1, x2)\n    assert K.int_shape(score) == y_shape")


# In[11]:


get_ipython().run_cell_magic('pytest', '', "\n#test_encoders.py\n\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input\nfrom keras_fcn.encoders import (\n    VGG16,\n    VGG19)\n\nfrom keras.utils.test_utils import keras_test\n\n\n@keras_test\ndef test_vgg16():\n    for data_format in ['channels_first', 'channels_last']:\n        K.set_image_data_format(data_format)\n        if K.image_data_format() == 'channels_first':\n            x = Input(shape=(3, 500, 500))\n            pool1_shape = (None, 64, 250, 250)\n            pool2_shape = (None, 128, 125, 125)\n            pool3_shape = (None, 256, 63, 63)\n            pool4_shape = (None, 512, 32, 32)\n            drop7_shape = (None, 4096, 16, 16)\n            conv1_weight = -0.35009676\n        else:\n            x = Input(shape=(500, 500, 3))\n            pool1_shape = (None, 250, 250, 64)\n            pool2_shape = (None, 125, 125, 128)\n            pool3_shape = (None, 63, 63, 256)\n            pool4_shape = (None, 32, 32, 512)\n            drop7_shape = (None, 16, 16, 4096)\n            conv1_weight = 0.429471\n\n        encoder = VGG16(x, weights='imagenet', trainable=False)\n        feat_pyramid = encoder.outputs\n\n        assert len(feat_pyramid) == 5\n\n        assert K.int_shape(feat_pyramid[0]) == drop7_shape\n        assert K.int_shape(feat_pyramid[1]) == pool4_shape\n        assert K.int_shape(feat_pyramid[2]) == pool3_shape\n        assert K.int_shape(feat_pyramid[3]) == pool2_shape\n        assert K.int_shape(feat_pyramid[4]) == pool1_shape\n\n        for layer in encoder.layers:\n            if layer.name == 'block1_conv1':\n                assert layer.trainable is False\n                weights = K.eval(layer.weights[0])\n                assert np.allclose(weights[0, 0, 0, 0], conv1_weight)\n\n        encoder_from_scratch = VGG16(x, weights=None, trainable=True)\n        for layer in encoder_from_scratch.layers:\n            if layer.name == 'block1_conv1':\n                assert layer.trainable is True\n                weights = K.eval(layer.weights[0])\n                assert not np.allclose(weights[0, 0, 0, 0], conv1_weight)\n\n\n@keras_test\ndef test_vgg19():\n    for data_format in ['channels_first', 'channels_last']:\n        K.set_image_data_format(data_format)\n        if K.image_data_format() == 'channels_first':\n            x = Input(shape=(3, 500, 500))\n            pool1_shape = (None, 64, 250, 250)\n            pool2_shape = (None, 128, 125, 125)\n            pool3_shape = (None, 256, 63, 63)\n            pool4_shape = (None, 512, 32, 32)\n            drop7_shape = (None, 4096, 16, 16)\n            conv1_weight = -0.35009676\n        else:\n            x = Input(shape=(500, 500, 3))\n            pool1_shape = (None, 250, 250, 64)\n            pool2_shape = (None, 125, 125, 128)\n            pool3_shape = (None, 63, 63, 256)\n            pool4_shape = (None, 32, 32, 512)\n            drop7_shape = (None, 16, 16, 4096)\n            conv1_weight = 0.429471\n\n        encoder = VGG19(x, weights='imagenet', trainable=False)\n        feat_pyramid = encoder.outputs\n\n        assert len(feat_pyramid) == 5\n\n        assert K.int_shape(feat_pyramid[0]) == drop7_shape\n        assert K.int_shape(feat_pyramid[1]) == pool4_shape\n        assert K.int_shape(feat_pyramid[2]) == pool3_shape\n        assert K.int_shape(feat_pyramid[3]) == pool2_shape\n        assert K.int_shape(feat_pyramid[4]) == pool1_shape\n\n        for layer in encoder.layers:\n            if layer.name == 'block1_conv1':\n                assert layer.trainable is False\n                weights = K.eval(layer.weights[0])\n                assert np.allclose(weights[0, 0, 0, 0], conv1_weight)\n\n        encoder_from_scratch = VGG19(x, weights=None, trainable=True)\n        for layer in encoder_from_scratch.layers:\n            if layer.name == 'block1_conv1':\n                assert layer.trainable is True\n                weights = K.eval(layer.weights[0])\n                assert not np.allclose(weights[0, 0, 0, 0], conv1_weight)")


# In[12]:


get_ipython().run_cell_magic('pytest', '', "\n#test_decoders.py\n\nimport pytest\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input\nfrom keras_fcn.decoders import (\n    Decoder,\n    VGGDecoder,\n    VGGUpsampler\n)\n\nfrom keras.utils.test_utils import keras_test\n\n\ndef test_decoder():\n    with pytest.raises(ValueError):\n        Decoder(pyramid=['fake1', 'fake2'], blocks=['fake1'])\n\n\ndef test_vgg_decoder():\n    if K.image_data_format() == 'channels_last':\n        inputs = Input(shape=(500, 500, 3))\n        pool3 = Input(shape=(88, 88, 256))\n        pool4 = Input(shape=(44, 44, 512))\n        drop7 = Input(shape=(16, 16, 4096))\n        score_shape = (None, 500, 500, 21)\n    else:\n        inputs = Input(shape=(3, 500, 500))\n        pool3 = Input(shape=(256, 88, 88))\n        pool4 = Input(shape=(512, 44, 44))\n        drop7 = Input(shape=(4096, 16, 16))\n        score_shape = (None, 21, 500, 500)\n    pyramid = [drop7, pool4, pool3, inputs]\n    scales = [1., 1e-2, 1e-4]\n    score = VGGDecoder(pyramid, scales, classes=21)\n    assert K.int_shape(score) == score_shape\n\n\ndef test_vgg_upsampler():\n    if K.image_data_format() == 'channels_last':\n        inputs = Input(shape=(500, 500, 3))\n        pool3 = Input(shape=(63, 63, 256))\n        pool4 = Input(shape=(32, 32, 512))\n        drop7 = Input(shape=(16, 16, 4096))\n        score_shape = (None, 500, 500, 21)\n    else:\n        inputs = Input(shape=(3, 500, 500))\n        pool3 = Input(shape=(256, 63, 63))\n        pool4 = Input(shape=(512, 32, 32))\n        drop7 = Input(shape=(4096, 16, 16))\n        score_shape = (None, 21, 500, 500)\n    pyramid = [drop7, pool4, pool3, inputs]\n    scales = [1., 1e-2, 1e-4]\n    score = VGGUpsampler(pyramid, scales, classes=21)\n    assert K.int_shape(score) == score_shape")


# In[8]:


get_ipython().run_cell_magic('pytest', '', '\n#test_models.py\n\n"""Test FCN."""\nimport numpy as np\nfrom keras_fcn import FCN\nfrom keras import backend as K\n\ndef is_same_shape(shape, expected_shape, data_format=None):\n    """Test helper."""\n    if data_format is None:\n        data_format = K.image_data_format()\n    if data_format == \'channels_first\':\n        expected_shape = (expected_shape[0],\n                          expected_shape[3],\n                          expected_shape[1],\n                          expected_shape[2])\n    return shape == expected_shape\n\n\ndef test_fcn_vgg16_shape():\n    """Test output shape."""\n    if K.image_data_format() == \'channels_first\':\n        input_shape = (3, 500, 500)\n    else:\n        input_shape = (500, 500, 3)\n    fcn_vgg16 = FCN(input_shape=input_shape, classes=21)\n\n    layers = [l.name for l in fcn_vgg16.layers]\n    assert \'upscore_feat1\' in layers\n    assert \'upscore_feat2\' in layers\n    assert \'upscore_feat3\' in layers\n\n    for l in fcn_vgg16.layers:\n        if l.name == \'block1_pool\':\n            test_shape = (None, 250, 250, 64)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block2_pool\':\n            test_shape = (None, 125, 125, 128)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block3_pool\':\n            test_shape = (None, 63, 63, 256)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block4_pool\':\n            test_shape = (None, 32, 32, 512)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block5_pool\':\n            test_shape = (None, 16, 16, 512)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'dropout_2\':\n            test_shape = (None, 16, 16, 4096)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'upscore_feat1\':\n            test_shape = (None, 32, 32, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'upscore_feat2\':\n            test_shape = (None, 63, 63, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'upscore_feat3\':\n            test_shape = (None, 500, 500, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'score\':\n            test_shape = (None, 500, 500, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n    assert is_same_shape(fcn_vgg16.output_shape, (None, 500, 500, 21))\n\n    input_shape = (1366, 768, 3)\n    fcn_vgg16 = FCN(input_shape=input_shape, classes=21)\n    assert is_same_shape(fcn_vgg16.output_shape, (None, 1366, 768, 21))\n\n\ndef test_fcn_vgg16_correctness():\n    """Test output not NaN."""\n    if K.image_data_format() == \'channels_first\':\n        input_shape = (3, 500, 500)\n        x = np.random.rand(1, 3, 500, 500)\n        y = np.random.randint(21, size=(1, 500, 500))\n        y = np.eye(21)[y]\n        y = np.transpose(y, (0, 3, 1, 2))\n    else:\n        input_shape = (500, 500, 3)\n        x = np.random.rand(1, 500, 500, 3)\n        y = np.random.randint(21, size=(1, 500, 500))\n        y = np.eye(21)[y]\n    fcn_vgg16 = FCN(classes=21, input_shape=input_shape)\n    fcn_vgg16.compile(optimizer=\'rmsprop\',\n                      loss=\'categorical_crossentropy\',\n                      metrics=[\'accuracy\'])\n    fcn_vgg16.fit(x, y, batch_size=1, epochs=1)\n    loss = fcn_vgg16.evaluate(x, y, batch_size=1)\n    assert not np.any(np.isinf(loss))\n    assert not np.any(np.isnan(loss))\n    y_pred = fcn_vgg16.predict(x, batch_size=1)\n    assert not np.any(np.isinf(y_pred))\n    assert not np.any(np.isnan(y_pred))')


# In[13]:


get_ipython().run_cell_magic('pytest', '', "\n#test_losses.py\n\nimport numpy as np\nimport keras.backend as K\nfrom keras_fcn.losses import mean_categorical_crossentropy\n\n\ndef test_categorical_crossentropy():\n\n    y_true = np.reshape([1, 1, 0, 0], [1, 2, 2]).astype('int')\n    y_true = np.eye(2)[y_true]\n    y_pred = np.ones((1, 2, 2, 2)) * 0.5\n\n    y_true, y_pred = K.variable(y_true), K.variable(y_pred)\n\n    loss = mean_categorical_crossentropy(y_true, y_pred)\n    loss = K.eval(loss)\n    assert np.allclose(loss, 0.69314718)")


# ## Test NeMO adapted keras-fcn

# In[24]:


sys.path.append('./utils/')
import loadcoraldata_utils as coralutils
import NeMO_backend
import NeMO_layers
import NeMO_blocks
import NeMO_encoders
import NeMO_decoders
import NeMO_models
import NeMO_losses
import NeMO_callbacks


# In[18]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_layers_test\n\nimport pytest\nimport numpy as np\nimport keras.backend as K\nimport sys\nsys.path.append("..") # Adds higher directory to python modules path.\nfrom NeMO_layers import CroppingLike2D, BilinearUpSampling2D\nfrom keras.utils.test_utils import keras_test\n\n\n@keras_test\ndef test_bilinear_upsampling_2d():\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 5\n    input_len_dim2 = 5\n    target_len_dim1 = 8\n    target_len_dim2 = 8\n\n    for data_format in [\'channels_first\', \'channels_last\']:\n        if data_format == \'channels_first\':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2)\n            target = np.random.rand(num_samples, stack_size,\n                                    target_len_dim1, target_len_dim2)\n            expected_output_shape = (2, 2, 8, 8)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    stack_size)\n            target = np.random.rand(num_samples, target_len_dim1,\n                                    target_len_dim2, stack_size)\n            expected_output_shape = (2, 8, 8, 2)\n        # shape test\n        layer = BilinearUpSampling2D(target_shape=target.shape,\n                                     data_format=data_format)\n        output = layer(K.variable(inputs))\n        assert K.int_shape(output) == expected_output_shape\n\n\n@keras_test\ndef test_cropping_like_2d():\n    num_samples = 2\n    stack_size = 2\n    input_len_dim1 = 9\n    input_len_dim2 = 9\n    target_len_dim1 = 5\n    target_len_dim2 = 5\n    offset = (2, 2)\n\n    for data_format in [\'channels_first\', \'channels_last\']:\n        if data_format == \'channels_first\':\n            inputs = np.random.rand(num_samples, stack_size,\n                                    input_len_dim1, input_len_dim2)\n            target = np.random.rand(num_samples, stack_size,\n                                    target_len_dim1, target_len_dim2)\n            invalid_target = np.random.rand(num_samples, stack_size,\n                                            input_len_dim1 + 1,\n                                            input_len_dim2 + 1)\n            expected_output = inputs[:,\n                                     :,\n                                     offset[0]: offset[0] + target_len_dim1,\n                                     offset[1]: offset[1] + target_len_dim2]\n            expected_output_shape = (2, 2, 5, 5)\n        else:\n            inputs = np.random.rand(num_samples,\n                                    input_len_dim1, input_len_dim2,\n                                    stack_size)\n            target = np.random.rand(num_samples, target_len_dim1,\n                                    target_len_dim2, stack_size)\n            invalid_target = np.random.rand(num_samples, input_len_dim1 + 1,\n                                            input_len_dim2 + 1, stack_size)\n            expected_output = inputs[:,\n                                     offset[0]: offset[0] + target_len_dim1,\n                                     offset[1]: offset[1] + target_len_dim2,\n                                     :]\n            expected_output_shape = (2, 5, 5, 2)\n        # basic test\n        layer = CroppingLike2D(target_shape=target.shape,\n                               offset=2, data_format=data_format)\n        assert layer.offset == (2, 2)\n        layer = CroppingLike2D(target_shape=target.shape,\n                               offset=offset, data_format=data_format)\n        # correctness test\n        output = layer(K.variable(inputs))\n        assert K.int_shape(output) == expected_output_shape\n        np_output = K.eval(output)\n        assert np.allclose(np_output, expected_output)\n        # \'centered\' test\n        layer = CroppingLike2D(target_shape=target.shape,\n                               offset=\'centered\', data_format=data_format)\n        output = layer(K.variable(inputs))\n        np_output = K.eval(output)\n        assert np.allclose(np_output, expected_output)\n\n        # Test invalid use cases\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=target.shape,\n                                   offset=(5, 2),\n                                   data_format=data_format)\n            output = layer(K.variable(inputs))\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=target.shape,\n                                   offset=(2, 5),\n                                   data_format=data_format)\n            output = layer(K.variable(inputs))\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=target.shape,\n                                   offset=[3, 3, 3],\n                                   data_format=data_format)\n        with pytest.raises(ValueError):\n            layer = CroppingLike2D(target_shape=invalid_target.shape,\n                                   offset=\'centered\', data_format=data_format)\n            output = layer(K.variable(inputs))')


# In[19]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_blocks_test\n\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input\nimport sys\nsys.path.append("..") # Adds higher directory to python modules path.\nfrom NeMO_blocks import (\n    vgg_conv,\n    vgg_fc,\n    vgg_deconv,\n    vgg_score\n)\n\ndef test_vgg_conv():\n    if K.image_data_format() == \'channels_first\':\n        x = Input(shape=(3, 224, 224))\n        y1_shape = (None, 64, 112, 112)\n        y2_shape = (None, 128, 56, 56)\n    else:\n        x = Input(shape=(224, 224, 3))\n        y1_shape = (None, 112, 112, 64)\n        y2_shape = (None, 56, 56, 128)\n\n    block1 = vgg_conv(filters=64, convs=2, block_name=\'block1\')\n    y = block1(x)\n    assert K.int_shape(y) == y1_shape\n\n    block2 = vgg_conv(filters=128, convs=2, block_name=\'block2\')\n    y = block2(y)\n    assert K.int_shape(y) == y2_shape\n\n\ndef test_vgg_fc():\n    if K.image_data_format() == \'channels_first\':\n        x1 = K.variable(np.random.random((1, 512, 14, 14)))\n        y1_shape = (1, 512, 8, 8)\n    else:\n        x1 = K.variable(np.random.random((1, 14, 14, 512)))\n        y1_shape = (1, 8, 8, 512)\n\n\ndef test_vgg_deconv():\n    if K.image_data_format() == \'channels_first\':\n        x1 = K.variable(np.random.random((1, 512, 8, 8)))\n        y1_shape = (1, 21, 18, 18)\n        x2 = K.variable(np.random.random((1, 512, 27, 27)))\n        y2_shape = (1, 21, 38, 38)\n        x3 = K.variable(np.random.random((1, 256, 53, 53)))\n        y3_shape = (1, 21, 312, 312)\n    else:\n        x1 = K.variable(np.random.random((1, 8, 8, 512)))\n        y1_shape = (1, 18, 18, 21)\n        x2 = K.variable(np.random.random((1, 27, 27, 512)))\n        y2_shape = (1, 38, 38, 21)\n        x3 = K.variable(np.random.random((1, 53, 53, 256)))\n        y3_shape = (1, 312, 312, 21)\n\n    upscore1 = vgg_deconv(classes=21)(x1, None)\n    assert K.int_shape(upscore1) == y1_shape\n    assert not np.any(np.isnan(K.eval(upscore1)))\n\n    upscore2 = vgg_deconv(classes=21)(x2, upscore1)\n    assert K.int_shape(upscore2) == y2_shape\n    assert not np.any(np.isnan(K.eval(upscore2)))\n\n    upscore3 = vgg_deconv(classes=21, kernel_size=(16, 16),\n                          strides=(8, 8))(x3, upscore2)\n    assert K.int_shape(upscore3) == y3_shape\n    assert not np.any(np.isnan(K.eval(upscore3)))\n\n\ndef test_vgg_score():\n    if K.image_data_format() == \'channels_first\':\n        x1 = K.variable(np.random.random((1, 3, 224, 224)))\n        x2 = K.variable(np.random.random((1, 21, 312, 312)))\n        y_shape = (1, 21, 224, 224)\n    else:\n        x1 = K.variable(np.random.random((1, 224, 224, 3)))\n        x2 = K.variable(np.random.random((1, 312, 312, 21)))\n        y_shape = (1, 224, 224, 21)\n    score = vgg_score(crop_offset=\'centered\')(x1, x2)\n    assert K.int_shape(score) == y_shape')


# In[20]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_encoder_test\n\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input\nimport sys\nsys.path.append("..") # Adds higher directory to python modules path.\nfrom NeMO_encoders import (\n    VGG16,\n    VGG19)\n\nfrom keras.utils.test_utils import keras_test\n\n\n@keras_test\ndef test_vgg16():\n    for data_format in [\'channels_first\', \'channels_last\']:\n        K.set_image_data_format(data_format)\n        if K.image_data_format() == \'channels_first\':\n            x = Input(shape=(3, 500, 500))\n            pool1_shape = (None, 64, 250, 250)\n            pool2_shape = (None, 128, 125, 125)\n            pool3_shape = (None, 256, 63, 63)\n            pool4_shape = (None, 512, 32, 32)\n            drop7_shape = (None, 4096, 16, 16)\n            conv1_weight = -0.35009676\n        else:\n            x = Input(shape=(500, 500, 3))\n            pool1_shape = (None, 250, 250, 64)\n            pool2_shape = (None, 125, 125, 128)\n            pool3_shape = (None, 63, 63, 256)\n            pool4_shape = (None, 32, 32, 512)\n            drop7_shape = (None, 16, 16, 4096)\n            conv1_weight = 0.429471\n\n        encoder = VGG16(x, weights=\'imagenet\', trainable=False)\n        feat_pyramid = encoder.outputs\n\n        assert len(feat_pyramid) == 5\n\n        assert K.int_shape(feat_pyramid[0]) == drop7_shape\n        assert K.int_shape(feat_pyramid[1]) == pool4_shape\n        assert K.int_shape(feat_pyramid[2]) == pool3_shape\n        assert K.int_shape(feat_pyramid[3]) == pool2_shape\n        assert K.int_shape(feat_pyramid[4]) == pool1_shape\n\n        for layer in encoder.layers:\n            if layer.name == \'block1_conv1\':\n                assert layer.trainable is False\n                weights = K.eval(layer.weights[0])\n                assert np.allclose(weights[0, 0, 0, 0], conv1_weight)\n\n        encoder_from_scratch = VGG16(x, weights=None, trainable=True)\n        for layer in encoder_from_scratch.layers:\n            if layer.name == \'block1_conv1\':\n                assert layer.trainable is True\n                weights = K.eval(layer.weights[0])\n                assert not np.allclose(weights[0, 0, 0, 0], conv1_weight)\n\n\n@keras_test\ndef test_vgg19():\n    for data_format in [\'channels_first\', \'channels_last\']:\n        K.set_image_data_format(data_format)\n        if K.image_data_format() == \'channels_first\':\n            x = Input(shape=(3, 500, 500))\n            pool1_shape = (None, 64, 250, 250)\n            pool2_shape = (None, 128, 125, 125)\n            pool3_shape = (None, 256, 63, 63)\n            pool4_shape = (None, 512, 32, 32)\n            drop7_shape = (None, 4096, 16, 16)\n            conv1_weight = -0.35009676\n        else:\n            x = Input(shape=(500, 500, 3))\n            pool1_shape = (None, 250, 250, 64)\n            pool2_shape = (None, 125, 125, 128)\n            pool3_shape = (None, 63, 63, 256)\n            pool4_shape = (None, 32, 32, 512)\n            drop7_shape = (None, 16, 16, 4096)\n            conv1_weight = 0.429471\n\n        encoder = VGG19(x, weights=\'imagenet\', trainable=False)\n        feat_pyramid = encoder.outputs\n\n        assert len(feat_pyramid) == 5\n\n        assert K.int_shape(feat_pyramid[0]) == drop7_shape\n        assert K.int_shape(feat_pyramid[1]) == pool4_shape\n        assert K.int_shape(feat_pyramid[2]) == pool3_shape\n        assert K.int_shape(feat_pyramid[3]) == pool2_shape\n        assert K.int_shape(feat_pyramid[4]) == pool1_shape\n\n        for layer in encoder.layers:\n            if layer.name == \'block1_conv1\':\n                assert layer.trainable is False\n                weights = K.eval(layer.weights[0])\n                assert np.allclose(weights[0, 0, 0, 0], conv1_weight)\n\n        encoder_from_scratch = VGG19(x, weights=None, trainable=True)\n        for layer in encoder_from_scratch.layers:\n            if layer.name == \'block1_conv1\':\n                assert layer.trainable is True\n                weights = K.eval(layer.weights[0])\n                assert not np.allclose(weights[0, 0, 0, 0], conv1_weight)')


# In[21]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_decoder_test\n\nimport pytest\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input\nimport sys\nsys.path.append("..") # Adds higher directory to python modules path.\nfrom NeMO_decoders import (\n    Decoder,\n    VGGDecoder,\n    VGGUpsampler\n)\n\nfrom keras.utils.test_utils import keras_test\n\n\ndef test_decoder():\n    with pytest.raises(ValueError):\n        Decoder(pyramid=[\'fake1\', \'fake2\'], blocks=[\'fake1\'])\n\n\ndef test_vgg_decoder():\n    if K.image_data_format() == \'channels_last\':\n        inputs = Input(shape=(500, 500, 3))\n        pool3 = Input(shape=(88, 88, 256))\n        pool4 = Input(shape=(44, 44, 512))\n        drop7 = Input(shape=(16, 16, 4096))\n        score_shape = (None, 500, 500, 21)\n    else:\n        inputs = Input(shape=(3, 500, 500))\n        pool3 = Input(shape=(256, 88, 88))\n        pool4 = Input(shape=(512, 44, 44))\n        drop7 = Input(shape=(4096, 16, 16))\n        score_shape = (None, 21, 500, 500)\n    pyramid = [drop7, pool4, pool3, inputs]\n    scales = [1., 1e-2, 1e-4]\n    score = VGGDecoder(pyramid, scales, classes=21)\n    assert K.int_shape(score) == score_shape\n\n\ndef test_vgg_upsampler():\n    if K.image_data_format() == \'channels_last\':\n        inputs = Input(shape=(500, 500, 3))\n        pool3 = Input(shape=(63, 63, 256))\n        pool4 = Input(shape=(32, 32, 512))\n        drop7 = Input(shape=(16, 16, 4096))\n        score_shape = (None, 500, 500, 21)\n    else:\n        inputs = Input(shape=(3, 500, 500))\n        pool3 = Input(shape=(256, 63, 63))\n        pool4 = Input(shape=(512, 32, 32))\n        drop7 = Input(shape=(4096, 16, 16))\n        score_shape = (None, 21, 500, 500)\n    pyramid = [drop7, pool4, pool3, inputs]\n    scales = [1., 1e-2, 1e-4]\n    score = VGGUpsampler(pyramid, scales, classes=21)\n    assert K.int_shape(score) == score_shape\n\n')


# In[22]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_model_test\n\n"""Test FCN."""\nimport numpy as np\nimport sys\nsys.path.append("..") # Adds higher directory to python modules path.\nfrom NeMO_models import FCN\nfrom keras import backend as K\n\n\ndef is_same_shape(shape, expected_shape, data_format=None):\n    """Test helper."""\n    if data_format is None:\n        data_format = K.image_data_format()\n    if data_format == \'channels_first\':\n        expected_shape = (expected_shape[0],\n                          expected_shape[3],\n                          expected_shape[1],\n                          expected_shape[2])\n    return shape == expected_shape\n\n\ndef test_fcn_vgg16_shape():\n    """Test output shape."""\n    if K.image_data_format() == \'channels_first\':\n        input_shape = (3, 500, 500)\n    else:\n        input_shape = (500, 500, 3)\n    fcn_vgg16 = FCN(input_shape=input_shape, classes=21)\n\n    layers = [l.name for l in fcn_vgg16.layers]\n    assert \'upscore_feat1\' in layers\n    assert \'upscore_feat2\' in layers\n    assert \'upscore_feat3\' in layers\n\n    for l in fcn_vgg16.layers:\n        if l.name == \'block1_pool\':\n            test_shape = (None, 250, 250, 64)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block2_pool\':\n            test_shape = (None, 125, 125, 128)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block3_pool\':\n            test_shape = (None, 63, 63, 256)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block4_pool\':\n            test_shape = (None, 32, 32, 512)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'block5_pool\':\n            test_shape = (None, 16, 16, 512)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'dropout_2\':\n            test_shape = (None, 16, 16, 4096)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'upscore_feat1\':\n            test_shape = (None, 32, 32, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'upscore_feat2\':\n            test_shape = (None, 63, 63, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'upscore_feat3\':\n            test_shape = (None, 500, 500, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n        elif l.name == \'score\':\n            test_shape = (None, 500, 500, 21)\n            assert is_same_shape(l.output_shape, test_shape)\n    assert is_same_shape(fcn_vgg16.output_shape, (None, 500, 500, 21))\n\n    input_shape = (1366, 768, 3)\n    fcn_vgg16 = FCN(input_shape=input_shape, classes=21)\n    assert is_same_shape(fcn_vgg16.output_shape, (None, 1366, 768, 21))\n\n\ndef test_fcn_vgg16_correctness():\n    """Test output not NaN."""\n    if K.image_data_format() == \'channels_first\':\n        input_shape = (3, 500, 500)\n        x = np.random.rand(1, 3, 500, 500)\n        y = np.random.randint(21, size=(1, 500, 500))\n        y = np.eye(21)[y]\n        y = np.transpose(y, (0, 3, 1, 2))\n    else:\n        input_shape = (500, 500, 3)\n        x = np.random.rand(1, 500, 500, 3)\n        y = np.random.randint(21, size=(1, 500, 500))\n        y = np.eye(21)[y]\n    fcn_vgg16 = FCN(classes=21, input_shape=input_shape)\n    fcn_vgg16.compile(optimizer=\'rmsprop\',\n                      loss=\'categorical_crossentropy\',\n                      metrics=[\'accuracy\'])\n    fcn_vgg16.fit(x, y, batch_size=1, epochs=1)\n    loss = fcn_vgg16.evaluate(x, y, batch_size=1)\n    assert not np.any(np.isinf(loss))\n    assert not np.any(np.isnan(loss))\n    y_pred = fcn_vgg16.predict(x, batch_size=1)\n    assert not np.any(np.isinf(y_pred))\n    assert not np.any(np.isnan(y_pred))')


# In[25]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_losses_test\n\nimport numpy as np\nimport keras.backend as K\nimport sys\nsys.path.append("..") # Adds higher directory to python modules path.\nfrom NeMO_losses import mean_categorical_crossentropy\n\n\ndef test_categorical_crossentropy():\n\n    y_true = np.reshape([1, 1, 0, 0], [1, 2, 2]).astype(\'int\')\n    y_true = np.eye(2)[y_true]\n    y_pred = np.ones((1, 2, 2, 2)) * 0.5\n\n    y_true, y_pred = K.variable(y_true), K.variable(y_pred)\n\n    loss = mean_categorical_crossentropy(y_true, y_pred)\n    loss = K.eval(loss)\n    assert np.allclose(loss, 0.69314718)')


# In[26]:


get_ipython().run_cell_magic('pytest', '', '\n# NeMO_generator_test\n\n"""Pascal VOC Segmenttion Generator."""\nfrom __future__ import unicode_literals\nimport os\nimport numpy as np\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import (\n    ImageDataGenerator,\n    Iterator,\n    load_img,\n    img_to_array,\n    pil_image,\n    array_to_img)\n\n\nclass NeMOImageGenerator(ImageDataGenerator):\n    """A real-time data augmentation generator for NeMO-Net Images"""\n\n    def __init__(self,\n                 image_shape=(100, 100, 3),\n                 image_resample=True,\n                 pixelwise_center=False,\n                 pixel_mean=(0., 0., 0.),\n                 pixelwise_std_normalization=False,\n                 pixel_std=(1., 1., 1.),\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 zca_whitening=False,\n                 rotation_range=0.,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode=\'nearest\',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 preprocessing_function=None,\n                 data_format=None):\n        """Init."""\n        self.image_shape = tuple(image_shape)\n        self.image_resample = image_resample\n        self.pixelwise_center = pixelwise_center\n        self.pixel_mean = np.array(pixel_mean)\n        self.pixelwise_std_normalization = pixelwise_std_normalization\n        self.pixel_std = np.array(pixel_std)\n        super(NeMOImageGenerator, self).__init__()\n\n    def standardize(self, x):\n        """Standardize image."""\n        if self.pixelwise_center:\n            x -= self.pixel_mean\n        if self.pixelwise_std_normalization:\n            x /= self.pixel_std\n        return super(NeMOImageGenerator, self).standardize(x) # If there are any other operations that needs to be performed on x in superclass\n\n    def flow_from_imageset(self, image_set_loader,\n                           class_mode=\'categorical\', classes=None,\n                           batch_size=1, shuffle=True, seed=None):\n        """NeMOImageGenerator."""\n        return IndexIterator(\n            image_set_loader, self,\n            class_mode=class_mode,\n            classes=classes,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed)\n\n\nclass IndexIterator(Iterator):\n    """Iterator over index."""\n\n    def __init__(self, image_set_loader, image_data_generator,\n                 class_mode=\'categorical\', classes=None,\n                 batch_size=1, shuffle=False, seed=None):\n        """Init."""\n        self.image_set_loader = image_set_loader\n        self.image_data_generator = image_data_generator\n\n        self.filenames = image_set_loader.filenames\n        self.image_shape = image_set_loader.image_shape\n\n        self.classes = classes\n        if class_mode == \'binary\':\n            label_shape = list(self.image_shape).pop(self.channel_axis - 1)\n            self.label_shape = tuple(label_shape)\n        elif class_mode == \'categorical\':\n            label_shape = list(self.image_shape)\n            label_shape[self.image_data_generator.channel_axis - 1] \\\n                = self.classes\n            self.label_shape = tuple(label_shape)\n\n        super(IndexIterator, self).__init__(len(self.filenames), batch_size,\n                                            shuffle, seed)\n\n    def next(self,labelkey=None):\n        """Next batch."""\n        with self.lock:\n            index_array, current_index, current_batch_size = next(\n                self.index_generator)\n        batch_x = np.zeros(\n            (current_batch_size,) + self.image_shape,\n            dtype=K.floatx())\n        batch_y = np.zeros(\n            (current_batch_size,) + self.label_shape,\n            dtype=np.int8)\n        #batch_y = np.reshape(batch_y, (current_batch_size, -1, self.classes))\n\n        for i, j in enumerate(index_array):\n            fn = self.filenames[j]\n            x = self.image_set_loader.load_img(fn)\n            x = self.image_data_generator.standardize(x)\n            batch_x[i] = x\n            y = self.image_set_loader.load_seg(fn,labelkey=labelkey)\n            y = to_categorical(y, self.classes).reshape(self.label_shape)\n            #y = np.reshape(y, (-1, self.classes))\n            batch_y[i] = y\n\n        # save augmented images to disk for debugging\n        #if self.image_set_loader.save_to_dir:\n        #    for i in range(current_batch_size):\n        #        x = batch_x[i]\n        #        y = batch_y[i].argmax(\n        #            self.image_data_generator.channel_axis - 1)\n        #        if self.image_data_generator.data_format == \'channels_first\':\n        #            y = y[np.newaxis, ...]\n        #        else:\n        #            y = y[..., np.newaxis]\n        #        self.image_set_loader.save(x, y, current_index + i)\n\n        return batch_x, batch_y\n\n\nclass ImageSetLoader(object):\n    """Helper class to load image data into numpy arrays."""\n\n    def __init__(self, image_set, image_dir, label_dir, target_size=(100, 100),\n                 image_format=\'jpg\', color_mode=\'rgb\', label_format=\'png\',\n                 data_format=None,\n                 save_to_dir=None, save_prefix=\'\', save_format=\'jpg\'):\n        """Init."""\n        if data_format is None:\n            data_format = K.image_data_format()\n        self.data_format = data_format\n        self.target_size = tuple(target_size)\n\n        if not os.path.exists(image_set):\n            raise IOError(\'Image set {} does not exist. Please provide a\'\n                          \'valid file.\'.format(image_set))\n        self.filenames = np.loadtxt(image_set, dtype=bytes)\n        try:\n            self.filenames = [fn.decode(\'utf-8\') for fn in self.filenames]\n        except AttributeError as e:\n            print(str(e), self.filenames[:5])\n        if not os.path.exists(image_dir):\n            raise IOError(\'Directory {} does not exist. Please provide a \'\n                          \'valid directory.\'.format(image_dir))\n        self.image_dir = image_dir\n        if label_dir and not os.path.exists(label_dir):\n            raise IOError(\'Directory {} does not exist. Please provide a \'\n                          \'valid directory.\'.format(label_dir))\n        self.label_dir = label_dir\n\n        white_list_formats = {\'png\', \'jpg\', \'jpeg\', \'bmp\'}\n        self.image_format = image_format\n        if self.image_format not in white_list_formats:\n            raise ValueError(\'Invalid image format:\', image_format,\n                             \'; expected "png", "jpg", "jpeg" or "bmp"\')\n        self.label_format = label_format\n        if self.label_format not in white_list_formats:\n            raise ValueError(\'Invalid image format:\', label_format,\n                             \'; expected "png", "jpg", "jpeg" or "bmp"\')\n\n        if color_mode not in {\'rgb\', \'grayscale\'}:\n            raise ValueError(\'Invalid color mode:\', color_mode,\n                             \'; expected "rgb" or "grayscale".\')\n        self.color_mode = color_mode\n        if self.color_mode == \'rgb\':\n            if self.data_format == \'channels_last\':\n                self.image_shape = self.target_size + (3,)\n            else:\n                self.image_shape = (3,) + self.target_size\n        else:\n            if self.data_format == \'channels_last\':\n                self.image_shape = self.target_size + (1,)\n            else:\n                self.image_shape = (1,) + self.target_size\n\n        self.grayscale = self.color_mode == \'grayscale\'\n\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_format = save_format\n\n    def load_img(self, fn):\n        """Image load method.\n\n        # Arguments\n            fn: filename of the image (without extension suffix)\n        # Returns\n            arr: numpy array of shape self.image_shape\n        """\n        img_path = os.path.join(self.image_dir,\n                                \'{}.{}\'.format(fn,\n                                               self.image_format))\n        if not os.path.exists(img_path):\n            raise IOError(\'Image {} does not exist.\'.format(img_path))\n        img = load_img(img_path, self.grayscale, self.target_size)\n        x = img_to_array(img, data_format=self.data_format)\n\n        return x\n\n    def load_seg(self, fn, labelkey=None):\n        """Segmentation load method.\n\n        # Arguments\n            fn: filename of the image (without extension suffix)\n        # Returns\n            arr: numpy array of shape self.target_size\n        """\n        label_path = os.path.join(self.label_dir,\n                                  \'{}.{}\'.format(fn, self.label_format))\n        img = pil_image.open(label_path)\n        if self.target_size:\n            wh_tuple = (self.target_size[1], self.target_size[0])\n        if img.size != wh_tuple:\n            img = img.resize(wh_tuple)\n        y = img_to_array(img, self.data_format)\n #       y[y == 255] = 0\n\n        if labelkey is not None:\n            item_counter = 0\n            for item in labelkey:\n                y[y == item ] = item_counter \n                item_counter+=1\n\n        return y\n\n    def save(self, x, y, index):\n        """Image save method."""\n        img = array_to_img(x, self.data_format, scale=True)\n        mask = array_to_img(y, self.data_format, scale=True)\n        img.paste(mask, (0, 0), mask)\n\n        fname = \'img_{prefix}_{index}_{hash}.{format}\'.format(\n            prefix=self.save_prefix,\n            index=index,\n            hash=np.random.randint(1e4),\n            format=self.save_format)\n        img.save(os.path.join(self.save_to_dir, fname))')

